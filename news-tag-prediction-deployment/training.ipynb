{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythainlp.util import normalize\n",
    "from pythainlp import thai_characters\n",
    "from pythainlp.corpus import thai_stopwords\n",
    "from pythainlp.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline # Import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('prachathai-67k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_labels = ['การเมือง','สิทธิมนุษยชน','คุณภาพชีวิต','ต่างประเทศ','สังคม',\n",
    "                    'สิ่งแวดล้อม','เศรษฐกิจ','วัฒนธรรม','แรงงาน','ความมั่นคง','ไอซีที','การศึกษา']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_list_to_columns(row):\n",
    "    classes = {c: int(c in row['labels']) for c in benchmark_labels}\n",
    "    return pd.Series(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = df.apply(expand_list_to_columns, axis=1)\n",
    "df = pd.concat([df, new_cols], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping = {\n",
    "    \"การเมือง\": \"politics\", \"สิทธิมนุษยชน\": \"human_rights\", \"คุณภาพชีวิต\": \"quality_of_life\",\n",
    "    \"ต่างประเทศ\": \"foreign_affairs\", \"สังคม\": \"society\", \"สิ่งแวดล้อม\": \"environment\",\n",
    "    \"เศรษฐกิจ\": \"economy\", \"วัฒนธรรม\": \"culture\", \"แรงงาน\": \"labor\",\n",
    "    \"ความมั่นคง\": \"security\", \"ไอซีที\": \"ict\", \"การศึกษา\": \"education\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns=column_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['full_body_text'] = df['title'] + df['body_text']\n",
    "target_col = list(column_mapping.values())\n",
    "df = df[['full_body_text'] + target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_PATTERN = r\"\"\"(?i)\\b((?:https?:(?:/{1,3}|[a-z0-9%])|[a-z0-9.\\-]+[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)/)(?:[^\\s()<>{}\\[\\]]+|\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\))+(?:\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’])|(?:(?<!@)[a-z0-9]+(?:[.\\-][a-z0-9]+)*[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)\\b/?(?!@)))\"\"\"\n",
    "SPECIAL_CHARS_PATTERN = r'[!@#$%^&*()\\-+=\\[\\]{};:\\'\",<.>/?\\\\|]\\n'\n",
    "WORDS_TO_REMOVE = ['ประชาไท', 'ฯ', '๑', '๒', '๓', '๔', '๕', '๖', '๗', '๘', '๙', '๐']\n",
    "THAI_STOPWORDS = thai_stopwords()\n",
    "THAI_CHARACTERS_ONLY = \"\".join(list(thai_characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_thai_tokenizer(text):\n",
    "\n",
    "    # 1. Normalize and clean the text\n",
    "    text = normalize(text)\n",
    "    text = re.sub(r'<[^>]+>', '', text) # Remove HTML\n",
    "    text = re.sub(URL_PATTERN, '', text) # Remove URLs\n",
    "    for word in WORDS_TO_REMOVE:\n",
    "        text = text.replace(word, '')\n",
    "    text = re.sub(SPECIAL_CHARS_PATTERN, '', text) # Remove special chars\n",
    "    \n",
    "    # 2. Keep only Thai characters and spaces\n",
    "    allowed_chars_pattern = f'[^{THAI_CHARACTERS_ONLY}\\s]'\n",
    "    text = re.sub(allowed_chars_pattern, '', text)\n",
    "    \n",
    "    # 3. Tokenize text\n",
    "    tokens = word_tokenize(text, keep_whitespace=False)\n",
    "    \n",
    "    # 4. Remove stopwords\n",
    "    filtered_tokens = [token for token in tokens if token not in THAI_STOPWORDS and token.strip() != '']\n",
    "    \n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['full_body_text']\n",
    "y = df[target_col]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {}\n",
    "metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training model for: politics ---\n",
      "--- Training model for: human_rights ---\n",
      "--- Training model for: quality_of_life ---\n",
      "--- Training model for: foreign_affairs ---\n",
      "--- Training model for: society ---\n",
      "--- Training model for: environment ---\n",
      "--- Training model for: economy ---\n",
      "--- Training model for: culture ---\n",
      "--- Training model for: labor ---\n",
      "--- Training model for: security ---\n",
      "--- Training model for: ict ---\n",
      "--- Training model for: education ---\n"
     ]
    }
   ],
   "source": [
    "for column in target_col:\n",
    "    print(f\"--- Training model for: {column} ---\")\n",
    "    \n",
    "    # Define the pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(\n",
    "            tokenizer=custom_thai_tokenizer,\n",
    "            max_features=200,\n",
    "            token_pattern=None # Let the custom tokenizer handle everything\n",
    "        )),\n",
    "        ('clf', LogisticRegression(\n",
    "            solver='lbfgs',\n",
    "            max_iter=5000\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # Fit the pipeline on the training data for the current label\n",
    "    pipeline.fit(X_train, y_train[column])\n",
    "    \n",
    "    # Store the entire fitted pipeline\n",
    "    pipelines[column] = pipeline\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Evaluation\n",
    "    accuracy = accuracy_score(y_test[column], y_pred)\n",
    "    precision = precision_score(y_test[column], y_pred)\n",
    "    recall = recall_score(y_test[column], y_pred)\n",
    "    aucroc = roc_auc_score(y_test[column], y_proba)\n",
    "    \n",
    "    metrics[column] = {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'aucroc': aucroc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance Metrics:\n",
      "                 accuracy  precision    recall    aucroc\n",
      "politics         0.729268   0.767987  0.764870  0.799957\n",
      "human_rights     0.826779   0.702520  0.379608  0.821566\n",
      "quality_of_life  0.852703   0.651456  0.290225  0.839945\n",
      "foreign_affairs  0.912137   0.717993  0.489098  0.914446\n",
      "society          0.868537   0.562963  0.042175  0.761955\n",
      "environment      0.894314   0.583463  0.242542  0.865515\n",
      "economy          0.927235   0.620525  0.238751  0.889854\n",
      "culture          0.936294   0.628906  0.172932  0.870061\n",
      "labor            0.970393   0.808581  0.631443  0.961830\n",
      "security         0.948078   0.642487  0.163158  0.852279\n",
      "ict              0.962439   0.695402  0.209343  0.911095\n",
      "education        0.963028   0.593583  0.206704  0.900011\n"
     ]
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame.from_dict(metrics, orient='index')\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving pipeline for: politics\n",
      "Saving pipeline for: human_rights\n",
      "Saving pipeline for: quality_of_life\n",
      "Saving pipeline for: foreign_affairs\n",
      "Saving pipeline for: society\n",
      "Saving pipeline for: environment\n",
      "Saving pipeline for: economy\n",
      "Saving pipeline for: culture\n",
      "Saving pipeline for: labor\n",
      "Saving pipeline for: security\n",
      "Saving pipeline for: ict\n",
      "Saving pipeline for: education\n"
     ]
    }
   ],
   "source": [
    "for column, pipeline in pipelines.items():\n",
    "    print(f\"Saving pipeline for: {column}\")\n",
    "    filepath = f'./BE/MODEL/{column}_pipeline.pickle'\n",
    "    with open(filepath, 'wb') as file:\n",
    "        pickle.dump(pipeline, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
